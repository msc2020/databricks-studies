{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e218f376-65f6-415f-8cd7-9289c260c374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Generative AI Application Evaluation and Governance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "- Implement an assistant that is (supposed to be) a specialist in psychological metrics\n",
    "\n",
    "- Classify Q&A using the metrics of an assistant specialized in the “Big Seven” personality traits\n",
    "\n",
    "- Evaluate with MLFlow a simple Q&A database using an LLM as a judge specialized in the “Big Seven” traits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23e25c5c-3159-42f8-b5d5-e07380c2ef84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e51b83c-d623-43be-aa4c-c03b770b7d83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %run ./setup_env/env_benchmark_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "450cdc9f-da05-451f-8f3d-9734df44b000",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load libraries"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from rich import print\n",
    "import json\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "203ca763-75d0-4bcc-851f-260cd5d168ba",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define constants"
    }
   },
   "outputs": [],
   "source": [
    "SERVING_MODELS = {\n",
    "    'gpt-5-1': 'databricks-gpt-5-1',  # disabled\n",
    "    'gpt-oss-20b': 'databricks-gpt-oss-20b',  # disabled\n",
    "    'meta-llama-8b': 'databricks-meta-llama-3-1-8b-instruct',  # enabled\n",
    "    'qwen-80b': 'databricks-qwen3-next-80b-a3b-instruct',  # enabled\n",
    "    'llama-maverick-400b': 'databricks-llama-4-maverick', # enabled\n",
    "    'gemma-12b': 'databricks-gemma-3-12b'  # enabled  \n",
    "}\n",
    "\n",
    "\n",
    "CATEGORIES_BIG_SEVEN_TRAITS = '''The model \"Big Seven\" model measure and describe human personality traits. The framework groups variation in personality into seven separate factors:\n",
    "\n",
    "Trait 1 - Openness: measures creativity, curiosity, and willingness to entertain new ideas.\n",
    "\n",
    "Trait 2 - Conscientiousness: measures self-control, diligence, and attention to detail.\n",
    "\n",
    "Trait 3 - Extraversion: measures boldness, energy, and social interactivity.\n",
    "\n",
    "Trait 4 - Agreeableness: measures kindness, helpfulness, and willingness to cooperate.\n",
    "\n",
    "Trait 5 - Neuroticism: measures depression, irritability, and proneness to anxiety.\n",
    "\n",
    "Trait 6 - Religiousness: measures religious feeling or belief.\n",
    "\n",
    "Trait 7 - Machiavellianism: measures a personality trait characterized by manipulation, indifference to morality, \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8ed4ec5-98e2-45b3-8f17-8812e86cae6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Utils    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61a8c7c7-4c48-498b-bec7-9c641759a16e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_llm_model(\n",
    "    llm_model: ChatDatabricks,\n",
    "    input_text: str,\n",
    "    system_prompt: str, \n",
    "    context=CATEGORIES_BIG_SEVEN_TRAITS\n",
    "    ) -> str:\n",
    "    '''Run a LLM model chat assistant from answer questions about the input text.'''\n",
    "\n",
    "    user_prompt_analised = f'''\n",
    "    [INST] Task: Classify the user's input messages according to the \"Big Seven traits\". Returns only one probable trait based on the category matches within the \"Big Seven traits informed into context. Return the number of categories that match the content: Trait 1, Trait 2, ... , Trait 7.\n",
    "\n",
    "    <BEGIN TRAIT CLASSIFICATION EXAMPLE>\n",
    "    Question: \"What do you think about other people's feelings?\"\n",
    "    Bot Answer: 'I sympathise with others feelings.',\n",
    "    Probabable trait: 'Trait 4',\n",
    "    <END TRAIT CLASSIFICATION EXAMPLE>\n",
    "    \n",
    "    <BEGIN TRAIT CONTENT CATEGORIES>\n",
    "    {context}\n",
    "    <END TRAIT CONTENT CATEGORIES>\n",
    "    <BEGIN CONVERSATION>\n",
    "    {input_text}\n",
    "    <END CONVERSATION>\n",
    "    \n",
    "    <BEGIN CLASSIFICATION>    \n",
    "    Classification: Probabable trait: *Trait_i*\n",
    "    <END CLASSIFICATION>\n",
    "    '''\n",
    "    \n",
    "    res = llm_model.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=input_text)\n",
    "    ])\n",
    "    \n",
    "    print(res.content)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def run_llm_bot(llm_model: ChatDatabricks, input_text: str) -> str:\n",
    "    '''Run a LLM model for answer the input questions.'''\n",
    "\n",
    "    system_prompt='''\n",
    "    You are a helpful assistant that classify and answer the questions. Classify the typeof question. Be concise, consistent, and knowledgeable. Return as answer any of the traits classification of the input question according to the \"Big Seven traits {COMPLETE_GRADING_PROMPT_BIG_SEVEN}.\n",
    "    '''\n",
    "    \n",
    "    res = llm_model.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=input_text)\n",
    "    ])\n",
    "    \n",
    "    # print(res.content)\n",
    "    \n",
    "    return res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "135a6a75-2680-4568-b1aa-70a296a4d00c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# endpoint_llm = SERVING_MODELS['qwen-80b']\n",
    "endpoint_llm = SERVING_MODELS['llama-maverick-400b']\n",
    "\n",
    "llm_model = ChatDatabricks(\n",
    "\tendpoint=endpoint_llm,\t\n",
    "    seed=42  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6042118-f630-435f-9b3a-da5d10f346b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Philosophical. \n",
       "\n",
       "The question <span style=\"color: #008000; text-decoration-color: #008000\">\"What is there immutable in the mutable?\"</span> is classified under the trait of Openness to Experience, as \n",
       "it requires the ability to think abstractly, consider complex ideas, and explore unconventional perspectives. It \n",
       "demands a level of intellectual curiosity and the capacity to ponder profound and philosophical questions.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Philosophical. \n",
       "\n",
       "The question \u001b[32m\"What is there immutable in the mutable?\"\u001b[0m is classified under the trait of Openness to Experience, as \n",
       "it requires the ability to think abstractly, consider complex ideas, and explore unconventional perspectives. It \n",
       "demands a level of intellectual curiosity and the capacity to ponder profound and philosophical questions.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = run_llm_bot(\n",
    "    llm_model=llm_model,\n",
    "    input_text='What is there immutable in the mutable?'\n",
    ")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74e7d6f3-3107-4646-9a91-5f776fbb0943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Defining a custom metric to evaluate the LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "510cf274-1be6-4273-9ef5-5b6e32236788",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Explanation\n",
    "\n",
    "**Big Five \"Expanded\" personality traits (\"Big Seven\")**\n",
    "---\n",
    "\n",
    "- **Openness (O):** measures creativity, curiosity, and willingness to entertain new ideas.\n",
    "  - _Examples_:\n",
    "    - I have a rich vocabulary.\n",
    "    - I have a vivid imagination.\n",
    "    - I have excellent ideas.\n",
    "    - I am quick to understand things.\n",
    "    - I have difficulty understanding abstract ideas. (Reversed)\n",
    "    - I am not interested in abstract ideas. (Reversed)\n",
    "\n",
    "- **Conscientiousness (C):** measures self-control, diligence, and attention to detail.\n",
    "  - _Examples_:\n",
    "    - I am always prepared.\n",
    "    - I pay attention to details.\n",
    "    - I get chores done right away.\n",
    "    - I like order.\n",
    "    - I leave my belongings around. (Reversed)\n",
    "    - I make a mess of things. (Reversed)\n",
    "\n",
    "- **Extraversion (E)**: measures boldness, energy, and social interactivity.\n",
    "  - _Examples_:\n",
    "    - I am the life of the party.\n",
    "    - I feel comfortable around people.\n",
    "    - I start conversations.\n",
    "    - I talk to a lot of different people at parties.\n",
    "    - I do not talk a lot. (Reversed)\n",
    "    - I keep in the background. (Reversed)\n",
    "\n",
    "- **Agreeableness (A):** measures kindness, helpfulness, and willingness to cooperate.\n",
    "  - _Examples_:\n",
    "    - I am interested in people.\n",
    "    - I sympathise with others' feelings.\n",
    "    - I have a soft heart.\n",
    "    - I take time out for others.\n",
    "    - I am not really interested in others. (Reversed)\n",
    "    - I insult people. (Reversed)\n",
    "\n",
    "- **Neuroticism (N):** measures depression, irritability, and proneness to anxiety.\n",
    "\t- _Examples_:\n",
    "    - I get stressed out easily.\n",
    "    - I worry about things.\n",
    "    - I am easily disturbed.\n",
    "    - I get upset easily.\n",
    "    - I am relaxed most of the time. (Reversed)\n",
    "    - I seldom feel blue. (Reversed)\n",
    "\n",
    "- **_Religiousness_ (R):** measures religious feeling or belief.\n",
    "  - _Examples_:\n",
    "    - \"No man ever steps in the same river twice.\"\n",
    "    - \"What is real never ceases to exist, and what is not real never exists.\"\n",
    "    - \"Death is not the end, just a transition\"\n",
    "    - \"Your word is a lamp to my feet and a light for my path.\"\n",
    "  - \"Truly, truly, I say to you, unless a grain of wheat falls into the earth and dies, it remains unfruitful; but if it dies, it bears much fruit.\"\n",
    "\n",
    "- **_Machiavellianism_ (M):** measures a personality trait characterized by manipulation, indifference to morality, lack of empathy, and a calculated focus on self-interest.\n",
    "  - _Examples_:\n",
    "    - \"Never tell anyone the real reason you did something unless it is useful to do so.\" \n",
    "    - \"Most people are basically good and kind.\"\n",
    "    - \"The first method for estimating the intelligence of a ruler is to look at the men he has around him.\"\n",
    "    - \"To govern is to make people believe.\"\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** The traits **Religiousness (R)** and **Machiavellianism (M)** are to expand Big Five traits and try to better explain the human personality.\n",
    "\n",
    "**References:** \n",
    "  - https://en.wikipedia.org/wiki/Big_Five_personality_traits\n",
    "  - https://en.wikipedia.org/wiki/Impermanence_(Buddhism)\n",
    "  - https://en.wikipedia.org/wiki/Machiavellianism_(psychology)\n",
    "  - https://en.wikipedia.org/wiki/Religiosity\n",
    "  - https://en.wikipedia.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7c719f5-fc3f-4d60-be39-cd38c16e37ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define the Big Seven metric in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e1ac123-7b73-4593-a4ba-99f067748c9b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Tests for define a metric"
    }
   },
   "outputs": [],
   "source": [
    "def run_llm_model_metric(\n",
    "    llm_model: ChatDatabricks,\n",
    "    input_text: str,\n",
    "    system_prompt: str, \n",
    "    context=''\n",
    "    ) -> str:\n",
    "    '''Run a LLM model chat assistant from answer questions about the input text.'''\n",
    "\n",
    "    user_prompt_analised = f'''\n",
    "    [INST] Task: Generate a score for the user's input messages according to the classes of \"Big Seven traits\". This classes will be defined below. Returns only one a score with the probability of the trait belong to one of the categories matching with the \"Big Seven traits\".\n",
    "\n",
    "    <BEGIN TRAITS CLASSIFICATION EXAMPLE>\n",
    "    Question: \"What do you think about other people's feelings?\"\n",
    "    Bot Answer: 'I sympathise with others feelings.',\n",
    "    Probabable trait: '(Trait 4, 0.8)',\n",
    "    <END TRAIT CLASSIFICATION EXAMPLE>\n",
    "    \n",
    "    <BEGIN TRAITS CONTENT CATEGORIES>\n",
    "    {context}\n",
    "    <END TRAIT CONTENT CATEGORIES>\n",
    "\n",
    "    <BEGIN CONVERSATION>\n",
    "    {input_text}\n",
    "    <END CONVERSATION>\n",
    "    \n",
    "    <BEGIN OUTPUT>    \n",
    "    Score: 0.8\n",
    "    <END OUTPUT>\n",
    "    '''\n",
    "    \n",
    "    res = llm_model.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=input_text)\n",
    "    ])\n",
    "    \n",
    "    print(res.content)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def run_llm_bot_metric(llm_model: ChatDatabricks, input_text: str, context: str, verbose: bool = False) -> str:\n",
    "    '''Run a LLM model for answer the input questions.'''\n",
    "\n",
    "    system_prompt='''\n",
    "    You are a specialist at score traits of personality. Generate a one-sentence repsonse for the user's answer. \n",
    "    '''\n",
    "    \n",
    "    res = llm_model.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=input_text)\n",
    "    ])\n",
    "    \n",
    "    print(res.content) if verbose else None\n",
    "    \n",
    "    return res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27813b34-7b6e-4d5b-9acc-4ef38a7045b4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Grading prompt"
    }
   },
   "outputs": [],
   "source": [
    "METRIC_GRADING_PROMPT_BIG_SEVEN =(\n",
    "    'Big Seven: If the answer contains any notable aspects of personaility below are the details for differents scores:'\n",
    "    '- Score 1: The language contains aspects of creativity, curiosity, and willingness to entertain new ideas [Openness].'\n",
    "    '- Score 2: The language contains aspects of self-control, diligence, and attention to detail [Conscientiousness].'\n",
    "    '- Score 3: The language contains aspects of boldness, energy, and social interactivity [Extraversion].'\n",
    "    '- Score 4: The language contains aspects of kindness, helpfulness, and willingness to cooperate [Agreeableness].'\n",
    "    '- Score 5: The language contains aspects of depression, irritability, and proneness to anxiety [Neuroticism].'\n",
    "    '- Score 6: The language contains aspects of religious feeling or belief [Religiousness].'\n",
    "    '- Score 7: The language contains aspects of manipulation, indifference to morality, lack of empathy, and a calculated focus on self-interest [Machiavellianism].'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4fe94e5-4278-4e40-8c3c-85c4dd8b1666",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You tend to be understanding and empathetic towards others, often putting their emotional needs into consideration.'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_llm_bot_metric(\n",
    "    llm_model=llm_model, \n",
    "    input_text=\"What do you think about other people's feelings?\",\n",
    "    context=METRIC_GRADING_PROMPT_BIG_SEVEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff6f17ec-08d4-42ea-8333-5916016a9211",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "example1 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input=\"What do you think about other people's feelings?\",\n",
    "    output='I sympathise with others feelings.',\n",
    "    score=4,\n",
    "\tjustification='The language contains aspecs of the Big Seven traits model. Agreeableness.',\n",
    ")\n",
    "\n",
    "example2 = mlflow.metrics.genai.EvaluationExample(\n",
    "    input='What is there immutable in the mutable?',\n",
    "    output='Maybe there is. This is old question in Philosophy.',\n",
    "    score=6,\n",
    "\tjustification='The language contains aspecs of the Big Seven traits model. Religiousness.'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5edb3d5-56f2-454e-8184-6b3b773df3c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "big_seven_metric = mlflow.metrics.genai.make_genai_metric(\n",
    "    name='big_seven_metric',\n",
    "    definition=(\n",
    "        'The Big Seven personality trait model is a pseudo-scientific model for measuring and describing human' 'personality traits based on language. The framework groups aspects of personality into seven separate' 'factors, all measured on a continuous scale.'\n",
    "    ),\n",
    "    grading_prompt=METRIC_GRADING_PROMPT_BIG_SEVEN,\n",
    "    examples=[example1, example2],\n",
    "    model=f'endpoints:/{endpoint_llm}',\n",
    "    parameters={'temperature': '0.0'},\n",
    "    aggregations=['mean', 'variance'],\n",
    "    greater_is_better=False,\n",
    "    include_input=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "549fd83f-b3b1-403a-b856-bf45075aaaa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Using the Big Seven Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23d1beba-e753-4ac6-8373-124a75428142",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is there immutable in the mutable?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you think about other people's feelings?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do yout think about this citation: `Exper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs\n",
       "0            What is there immutable in the mutable?\n",
       "1   What do you think about other people's feelings?\n",
       "2  What do yout think about this citation: `Exper..."
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_eval = {\n",
    "    'inputs': [\n",
    "        'What is there immutable in the mutable?',\n",
    "        \"What do you think about other people's feelings?\",\n",
    "        \"What do yout think about this citation: `Experience is not what happens to a person; it's what a person does with what happens to it.`?\"\n",
    "    ]\n",
    "}\n",
    "dataset_eval = pd.DataFrame(examples_eval)\n",
    "dataset_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "763b4bd7-9ee1-4b1b-827f-1fa1870cdc37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def iterate_over_inputs(df: pd.DataFrame, context: str = METRIC_GRADING_PROMPT_BIG_SEVEN) -> list:\n",
    "    res = []\n",
    "    for _, df_i in df.iterrows():\n",
    "        res_llm = run_llm_bot_metric(\n",
    "            llm_model=llm_model,\n",
    "            input_text=df_i.inputs,\n",
    "            context=METRIC_GRADING_PROMPT_BIG_SEVEN\n",
    "        )\n",
    "        res.append(res_llm)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "706b9d79-132e-41a4-9a5d-fa80685ebe95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Your introspective question about the immutable in the mutable suggests a depth of self-awareness and a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">philosophical outlook, indicating a high level of Openness to Experience.'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'Your introspective question about the immutable in the mutable suggests a depth of self-awareness and a \u001b[0m\n",
       "\u001b[32mphilosophical outlook, indicating a high level of Openness to Experience.'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(iterate_over_inputs(dataset_eval.head(1), METRIC_GRADING_PROMPT_BIG_SEVEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a437f580-74a7-482b-9ea3-4a63b4ee5564",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Run evaluation on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "031d8de4-3315-4ba7-9109-4d5b68adda44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is there immutable in the mutable?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you think about other people's feelings?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do yout think about this citation: `Exper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs\n",
       "0            What is there immutable in the mutable?\n",
       "1   What do you think about other people's feelings?\n",
       "2  What do yout think about this citation: `Exper..."
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3842424c-9d93-4b40-b234-8c4634f6353d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/05 23:27:45 INFO mlflow.models.evaluation.evaluators.default: Computing model predictions.\n",
      "2026/02/05 23:27:47 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2026/02/05 23:27:47 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'exact_match' at index 4 in the `extra_metrics` parameter because it returned None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0102545c174444f592264d32a575b54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/05 23:27:48 WARNING mlflow.models.evaluation.utils.metric: Did not log metric 'exact_match' at index 4 in the `extra_metrics` parameter because it returned None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3baa1a61da45558f8e2d6b4ef70bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_eval = mlflow.evaluate(\n",
    "\titerate_over_inputs,\n",
    "\tdataset_eval,\n",
    "\tmodel_type='question-answering',\n",
    "\textra_metrics=[big_seven_metric]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65c94dea-14ae-4d5d-959e-b47c11a1745f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxicity/v1/mean</th>\n",
       "      <td>2.746301e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxicity/v1/variance</th>\n",
       "      <td>6.069935e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxicity/v1/p90</th>\n",
       "      <td>3.378253e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxicity/v1/ratio</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesch_kincaid_grade_level/v1/mean</th>\n",
       "      <td>1.551335e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesch_kincaid_grade_level/v1/variance</th>\n",
       "      <td>5.594180e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesch_kincaid_grade_level/v1/p90</th>\n",
       "      <td>1.789832e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ari_grade_level/v1/mean</th>\n",
       "      <td>1.774018e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ari_grade_level/v1/variance</th>\n",
       "      <td>1.843829e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ari_grade_level/v1/p90</th>\n",
       "      <td>1.892974e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_seven_metric/v1/mean</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_seven_metric/v1/variance</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "toxicity/v1/mean                        2.746301e-04\n",
       "toxicity/v1/variance                    6.069935e-09\n",
       "toxicity/v1/p90                         3.378253e-04\n",
       "toxicity/v1/ratio                       0.000000e+00\n",
       "flesch_kincaid_grade_level/v1/mean      1.551335e+01\n",
       "flesch_kincaid_grade_level/v1/variance  5.594180e+00\n",
       "flesch_kincaid_grade_level/v1/p90       1.789832e+01\n",
       "ari_grade_level/v1/mean                 1.774018e+01\n",
       "ari_grade_level/v1/variance             1.843829e+00\n",
       "ari_grade_level/v1/p90                  1.892974e+01\n",
       "big_seven_metric/v1/mean                         NaN\n",
       "big_seven_metric/v1/variance                     NaN"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame(results_eval.metrics, index=[0]).T\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3c6d314-4f3d-4855-ab9e-fe265a0b4d20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "05.4[lllm-as-a-judge]generative-ai-application-evaluation-and-governance",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
